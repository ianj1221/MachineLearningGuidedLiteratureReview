{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "204dbc45-0843-4aa1-8115-c3feb5384596",
   "metadata": {},
   "source": [
    "# 3.1.2 Classifier Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9729c5ab-94b5-4d28-ba72-7f29874d1a47",
   "metadata": {},
   "source": [
    "Use tensorflow to fit a model to the data using a dense neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849e70fd-ac6a-4eb0-ad39-f61ff8797c39",
   "metadata": {},
   "source": [
    "## Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290c4c4b-04e1-4616-8351-f66db46f9a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 20:01:40.237931: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b7b3b7-31c3-4be9-b2ce-233e8f043c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('2.1.2.TrainTestValData.npz', allow_pickle=True) as data:\n",
    "    train_ds_import = data['train']\n",
    "    train_labels = data['train_targets'].astype(np.int32)\n",
    "    test_ds_import = data['test']\n",
    "    test_labels = data['test_targets'].astype(np.int32)\n",
    "    val_ds_import = data['val']\n",
    "    val_labels = data['val_targets'].astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d501d1c-b8c2-4e0d-8805-95523a4f177e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((347, 1), (347,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_import.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d31dd38-b253-4d08-9ba2-588d076551c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 1, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e3a1669-e19d-4678-aa1a-3e07ac6d6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 20:08:02.851279: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-10 20:08:02.907338: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "raw_train_ds = tf.data.Dataset.from_tensor_slices((train_ds_import, train_labels))\n",
    "raw_test_ds = tf.data.Dataset.from_tensor_slices((test_ds_import, test_labels))\n",
    "raw_val_ds = tf.data.Dataset.from_tensor_slices((val_ds_import, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73239111-8c29-4972-bc43-c58f6c98778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "buffer_size = 10000\n",
    "\n",
    "\n",
    "raw_train_ds = raw_train_ds.shuffle(buffer_size).batch(batch_size)\n",
    "\n",
    "#raw_test_ds = raw_test_ds.shuffle(buffer_size)\n",
    "raw_test_ds = raw_test_ds.batch(test_ds_import.shape[0])\n",
    "\n",
    "#raw_val_ds = raw_val_ds.shuffle(buffer_size)\n",
    "raw_val_ds = raw_val_ds.batch(val_ds_import.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb4465-4e60-48fe-97b9-e95ec9940720",
   "metadata": {},
   "source": [
    "## Remove punctuation and tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd421d8-43e2-4a4d-b1d3-c7b8137da108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TA [b'Hydroxy functional alkyl polyurea crosslinkers \\rA hydroxy functional alkyl polyurea is disclosed having the formula presented in claim 1, wherein R comprises an isocyanurate moiety, biuret moiety, allophonate moiety, glycoluril moiety, benzoguanamine moiety, polyetheramine moiety, and/or polymeric moiety different from a polyetheramine and having an Mn of 500 or greater; wherein each RI is independently a hydrogen, alkyl having at least 1 carbon, or a hydroxy functional alkyl having 2 or more carbons and at least one R1 is a hydroxy functional alkyl having 2 or more carbons; and n is 2-6. Further disclosed is a coating comprising: a film-forming resin; and a hydroxy functional alkyl polyurea crosslinker having the formula presented in claim 4, wherein R2 is a substituted or unsubstituted C1 to C36 alkyl group, an aromatic group, an isocyanurate moiety, biuret moiety, allophonate moiety, glycoluril moiety, benzoguanamine moiety, polyetheramine moiety, and/or polymeric moiety different from a polyetheramine having an Mn of 500 or greater, wherein each R1 is independently a hydrogen, an alkyl having at least 1 carbon, or a hydroxy functional alkyl having 2 or more carbons and at least one R1 is a hydroxy functional alkyl having 2 or more carbons; and n is 2-6, and when R2 is a substituted or unsubstituted C1 to C36 alkyl group the film-forming resin comprises COOH functionality that reacts with the polyurea to form an ester linkage.Other hydroxy functional alkyl polyurea compounds, polymers made with the same, and compositions comprising the same are also disclosed as are substrates coated at least in part with or formed with any of the compositions described herein.\\r']\n",
      "Label 0\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "  for i in range(1):\n",
    "    print(\"TA\", text_batch.numpy()[i])\n",
    "    print(\"Label\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8bcb178-c619-4ba9-bd58-f3f6518a8a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html_1 = tf.strings.regex_replace(lowercase, '\\r', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html_1,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d889fe02-a029-45b1-973e-f12b9e270a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TA ['Formation of coating film \\rPURPOSE:To obtain a coating film excellent in smoothness, gloss and image clarity with a shortened coating stage in the 2-coat-1-bake method by a cationic electrodeposition coating and an org.-solvent coating by using an electrodeposition coating specified with the loss of coating film when heated and hardened. CONSTITUTION:A cationic electrodeposition coating A is applied to form a coating film, the surface of the unhardened film is coated with an org.-solvent coating, and both coating films are simultaneously hardened to form a double- layer coating film. The coating A with the coating film loss X controlled to 10wt.% when the dehydrated electrodeposition coating film is heated and hardened is used in this method. The electrodeposited film is not bled and the film is smoothly hardened by this method, and the desired coating film is obtained. The loss X is obtained by performing cationic electrodeposition under ordinary conditions, pulling up the obtained film from an electrodeposition bath, washing the coated surface with water, heating the film at 105 deg.C for 3hr to remove all or almost all the moisture in the film and then measuring the weight of the film. The coating film is then heated at 170 deg.C for 20min and then three-dimensionally cross-linked and hardened, and the weight of the coating film is measured to calculate the loss.\\r']\n",
      "Label 0\n",
      "Standardized TA tf.Tensor([b'formation of coating film  purposeto obtain a coating film excellent in smoothness gloss and image clarity with a shortened coating stage in the 2coat1bake method by a cationic electrodeposition coating and an orgsolvent coating by using an electrodeposition coating specified with the loss of coating film when heated and hardened constitutiona cationic electrodeposition coating a is applied to form a coating film the surface of the unhardened film is coated with an orgsolvent coating and both coating films are simultaneously hardened to form a double layer coating film the coating a with the coating film loss x controlled to 10wt when the dehydrated electrodeposition coating film is heated and hardened is used in this method the electrodeposited film is not bled and the film is smoothly hardened by this method and the desired coating film is obtained the loss x is obtained by performing cationic electrodeposition under ordinary conditions pulling up the obtained film from an electrodeposition bath washing the coated surface with water heating the film at 105 degc for 3hr to remove all or almost all the moisture in the film and then measuring the weight of the film the coating film is then heated at 170 degc for 20min and then threedimensionally crosslinked and hardened and the weight of the coating film is measured to calculate the loss '], shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# retrieve a batch (of 10 reviews and labels) from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_patent, first_label = train_ds_import[0], train_labels[0]\n",
    "print(\"TA\", first_patent)\n",
    "print(\"Label\", first_label)\n",
    "print(\"Standardized TA\", custom_standardization(first_patent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9b8c842-97c1-4a19-bf5c-127f77c1542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 500\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32e4b9b8-4ae7-4f3c-b1af-a306f77a044c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/anaconda-ai-2023-11/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "877b12be-8e59-4521-b2e5-9bebe2697d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acid',\n",
       " 'are',\n",
       " 'which',\n",
       " 'groups',\n",
       " 'be',\n",
       " 'parts',\n",
       " 'on',\n",
       " 'containing',\n",
       " 'coated',\n",
       " 'has',\n",
       " 'comprises',\n",
       " 'group',\n",
       " 'wherein',\n",
       " 'can',\n",
       " 'aqueous',\n",
       " 'relates',\n",
       " 'metal',\n",
       " 'corrosion',\n",
       " 'primer',\n",
       " 'material',\n",
       " 'more',\n",
       " 'c',\n",
       " 'curable',\n",
       " 'thereof',\n",
       " 'functional',\n",
       " 'surface',\n",
       " 'excellent',\n",
       " 'amine',\n",
       " 'adhesion',\n",
       " '1',\n",
       " 'such',\n",
       " 'layer',\n",
       " 'anticorrosive',\n",
       " 'andor',\n",
       " 'hydroxyl',\n",
       " 'first',\n",
       " 'applied',\n",
       " 'substrates',\n",
       " 'coatings',\n",
       " 'forming']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorize_layer.get_vocabulary()\n",
    "vocab[40:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e17eda0-c414-4056-9efc-d9f47e3b933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "  #text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bc77d72-6695-4f91-b29c-88a1a0c46e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TA tf.Tensor([b'Compositions of epoxy curing agent incorporating naphthol and naphthol derivatives \\rThe present invention relates to epoxy curing agent compositions comprising naphthol and naphthol derivatives in combination with at least one polyamine having three or more active amine hydrogens, and use of these curing agents as hardener for epoxy resins. These curing agent compositions may be used to cure, harden and/or crosslink an epoxy resin.\\r'], shape=(1,), dtype=string)\n",
      "Label tf.Tensor(0, shape=(), dtype=int32)\n",
      "Vectorized TA (<tf.Tensor: shape=(1, 500), dtype=int64, numpy=\n",
      "array([[  32,    5,   12,   30,   19,  676,  986,    4,  986,  692,    3,\n",
      "          34,   24,   55,    7,   12,   30,   19,   32,   28,  986,    4,\n",
      "         986,  692,   13,  302,   17,   16,   21,   25,  188,   22,  478,\n",
      "          14,   60,  277,   67, 1644,    4,   95,    5,  583,   30,  353,\n",
      "          26,  607,   15,   12,  219,  583,   30,   19,   32,  111,   44,\n",
      "         106,    7,  276, 2724,   73, 1298,    8,   12,   10,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "# retrieve a batch reviews and labels from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_patent, first_label = text_batch[0], label_batch[0]\n",
    "print(\"TA\", first_patent)\n",
    "print(\"Label\", first_label)\n",
    "print(\"Vectorized TA\", vectorize_text(first_patent, first_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08f43c8b-eb43-40b9-b417-b81221e28dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5729b7be-96c6-4606-9c06-5fce6e308447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review tf.Tensor(\n",
      "[ 461  619  131    6    4   81   23   63    3   24  232    2  461  619\n",
      "  131    6    4    2   81   23   63    3  461  619  131    6   50    8\n",
      "    2   20    4    2   29   20   52    3  343  159    5    3    2   20\n",
      "  333  493   40  143  140   10  522   19  693   19  505   19  476  854\n",
      " 1854   96  167  135 2147    4   97   52    3   20   29   11   30   19\n",
      "    3  121   86    5    3  461  619  131    6  122   18    3   24   53\n",
      "  486   60  112  637    3  461  619  131    6   49    3 1772    5   99\n",
      "  121   86    4    3  288    5    2   27   98   18 1558  397   46    2\n",
      "   56   33   53  486 3571  988  453  847    3  491  370    5    3   35\n",
      "   53  486   60  112  578 1228    4    3  535    5    3  619   35   11\n",
      " 1564  163    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0], shape=(500,), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "text_batch, label_batch = next(iter(train_ds))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "print(first_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64b791ad-f1a7-40b2-8de4-08a615ff4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63186ca5-d001-495c-ab32-333a69afe76a",
   "metadata": {},
   "source": [
    "## Tune hyperparameters of the neural network using Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3540f7a-750f-45ec-900b-6c5cda92f5f5",
   "metadata": {},
   "source": [
    "@misc{omalley2019kerastuner,\n",
    "    title        = {KerasTuner},\n",
    "    author       = {O'Malley, Tom and Bursztein, Elie and Long, James and Chollet, Fran\\c{c}ois and Jin, Haifeng and Invernizzi, Luca and others},\n",
    "    year         = 2019,\n",
    "    howpublished = {\\url{https://github.com/keras-team/keras-tuner}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90aa0df2-8193-4820-a162-ec22168b3e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f1c4c78ee30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(\n",
    "        input_dim = max_features, \n",
    "        output_dim = hp.Int(\"embedding_dim\", min_value=16, max_value=128, step=16)\n",
    "                           )),\n",
    "    if hp.Boolean(\"dropout_1\"):\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.5)),\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling1D()),\n",
    "    \n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice(f\"activation_{i}\", [\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout_2\"):\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.5))\n",
    "    model.add(tf.keras.layers.Dense(1)),\n",
    "    \n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-3, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer= tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss= tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics= tf.metrics.BinaryAccuracy(threshold=0.0),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_binary_accuracy',\n",
    "        restore_best_weights=True, \n",
    "        patience=5)\n",
    "build_model(keras_tuner.HyperParameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23cfa361-3196-4f20-acb7-7e5a38cc4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_binary_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"3.1.2.Classifier\",\n",
    "    project_name=\"Article_classifier\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76434b25-2dc7-4151-8879-ff19a65c7843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 02m 21s]\n",
      "val_binary_accuracy: 0.7631579041481018\n",
      "\n",
      "Best val_binary_accuracy So Far: 0.7894737124443054\n",
      "Total elapsed time: 04h 07m 12s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_ds, \n",
    "             epochs=30, \n",
    "             validation_data=val_ds,\n",
    "             callbacks=[early_stopping]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a2e99c-daeb-4537-ba38-3362a1b94067",
   "metadata": {},
   "source": [
    "## Examine the test accuracy of the top 10 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c33c842e-20cc-4787-aa71-864d85239c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 990ms/step - loss: 1.0669 - binary_accuracy: 0.7209\n",
      "Model 0 accuracy: 0.7209302186965942\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.5608 - binary_accuracy: 0.7674\n",
      "Model 1 accuracy: 0.7674418687820435\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.6453 - binary_accuracy: 0.8372\n",
      "Model 2 accuracy: 0.8372092843055725\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1c2bfe17e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.6311 - binary_accuracy: 0.7442\n",
      "Model 3 accuracy: 0.7441860437393188\n",
      "WARNING:tensorflow:6 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1c2bfe1f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.7794 - binary_accuracy: 0.7674\n",
      "Model 4 accuracy: 0.7674418687820435\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.7246 - binary_accuracy: 0.7674\n",
      "Model 5 accuracy: 0.7674418687820435\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.7150 - binary_accuracy: 0.7907\n",
      "Model 6 accuracy: 0.7906976938247681\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.6786 - binary_accuracy: 0.7209\n",
      "Model 7 accuracy: 0.7209302186965942\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 0.6074 - binary_accuracy: 0.6977\n",
      "Model 8 accuracy: 0.6976743936538696\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.5914 - binary_accuracy: 0.7209\n",
      "Model 9 accuracy: 0.7209302186965942\n"
     ]
    }
   ],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "for model in range(len(models)):\n",
    "    loss, accuracy = models[model].evaluate(test_ds)\n",
    "    print(f'Model {model} accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f839953-396f-4d07-8037-bb86fc45bd98",
   "metadata": {},
   "source": [
    "## Models 2 and 6 have ~80% test accuracy, package them and test on sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cee5a48a-3428-412c-9448-c834963499ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "    models[2],\n",
    "    tf.keras.layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "    optimizer=\"adam\", \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "export_model_6 = tf.keras.Sequential([\n",
    "    models[6],\n",
    "    tf.keras.layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "export_model_6.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "    optimizer=\"adam\", \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b4fa282-24df-4b1f-867d-7d0305bd978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = ['fast curing direct-to-metal corrosion resistant primer',\n",
    "                    'powder coating composition for metal substrates',\n",
    "                    'clear coat with high gloss and abrasion resistance',\n",
    "                    'electrodeposition coating']\n",
    "\n",
    "examples_vector = vectorize_layer(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23387ecd-8d2c-4d49-891f-b46ef339923b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[394  30 523 ...   0   0   0]\n",
      " [ 90   6   9 ...   0   0   0]\n",
      " [216 202  17 ...   0   0   0]\n",
      " [193   6   0 ...   0   0   0]], shape=(4, 500), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(examples_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7faae961-842a-468c-ab3f-cb58c28ef91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 606ms/step\n",
      "1/1 [==============================] - 1s 500ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.6304569 ],\n",
       "        [0.44846344],\n",
       "        [0.45617196],\n",
       "        [0.41814595]], dtype=float32),\n",
       " array([[0.8257912 ],\n",
       "        [0.52622527],\n",
       "        [0.54823023],\n",
       "        [0.4800891 ]], dtype=float32))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_model.predict(examples_vector), export_model_6.predict(examples_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1d02e-f4e5-4ad4-91d7-f2cde3bef5be",
   "metadata": {},
   "source": [
    "## Save the models and the vector layer and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae2eef39-e680-45df-a22e-00a2976bc454",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model.save(\"3.1.2.Model2.keras\")\n",
    "export_model_6.save('3.1.2.Model6.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6e76e63-e647-4228-9f44-c128c850a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46bb88ad-8300-4a78-bbad-7e6e8fd2f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({'config': vectorize_layer.get_config(),\n",
    "             'weights': vectorize_layer.get_weights()}\n",
    "            , open(\"3.1.2ClassifierVectorizeLayer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac206233-61e0-48ad-8833-a595748e8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save vocab\n",
    "vocab = pd.DataFrame(vectorize_layer.get_vocabulary())\n",
    "vocab.to_csv('3.1.2.vocab.txt', index = False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2023-11",
   "language": "python",
   "name": "conda-env-anaconda-ai-2023-11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
